"""
Phase 2 SQL generation caching for RoboPhD system.

This module implements run-scoped caching to prevent redundant API calls during
SQL generation. When the same prompt is sent to the same model with temperature=0.0,
we can reuse the cached SQL response, saving ~$0.01 per redundant call.

Only deterministic calls (temperature=0.0) are cached to ensure reproducibility.
"""

import hashlib
import json
import threading
from pathlib import Path
from typing import Optional, Dict


class Phase2CacheManager:
    """
    Manages run-scoped Phase 2 SQL generation caching.

    Cache is specific to a single research run (identified by run_dir).
    Cache keys are computed from API call parameters (prompts + model + temperature).
    Only deterministic (temperature=0.0) API responses are cached.
    """

    def __init__(self, run_dir: Path, agent_id: str):
        """
        Initialize cache manager for a research run and specific agent.

        Args:
            run_dir: Research run directory (e.g., research/robophd_20251111_141236)
            agent_id: Agent identifier (e.g., "iter31_agent_name")
        """
        self.run_dir = Path(run_dir)
        self.agent_id = agent_id
        self.cache_dir = self.run_dir / "cache" / "phase2_sql_generation" / agent_id
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        self.index_file = self.cache_dir / "index.json"
        self.index = self._load_index()

        # Statistics
        self.hits = 0
        self.misses = 0

        # Thread safety for parallel execution
        self._index_lock = threading.Lock()

    def _load_index(self) -> Dict:
        """Load cache index from disk."""
        if self.index_file.exists():
            with open(self.index_file, 'r') as f:
                return json.load(f)
        return {}

    def _save_index(self):
        """Save cache index to disk (thread-safe with atomic write)."""
        import tempfile
        import os

        with self._index_lock:
            # Write to temp file first, then atomic rename
            # This prevents corruption if process is interrupted mid-write
            temp_fd, temp_path = tempfile.mkstemp(
                dir=self.cache_dir,
                prefix='.index_tmp_',
                suffix='.json'
            )
            try:
                with os.fdopen(temp_fd, 'w') as f:
                    json.dump(self.index, f, indent=2)
                # Atomic rename (Unix)
                os.replace(temp_path, self.index_file)
            except Exception:
                # Clean up temp file on error
                try:
                    os.unlink(temp_path)
                except Exception:
                    pass
                raise

    def get_cache_key(self, system_prompt: str, user_prompt: str,
                      model: str, max_tokens: int, temperature: float) -> str:
        """
        Generate stable hash for API call parameters.

        Hash includes all parameters that affect the API response:
        - system_prompt: Full system prompt (Phase 1 output + eval_instructions)
        - user_prompt: Question + evidence + retry context
        - model: Model name (e.g., "claude-sonnet-4-5-20250929")
        - max_tokens: Maximum tokens in response
        - temperature: Sampling temperature

        Args:
            system_prompt: System prompt text
            user_prompt: User prompt text
            model: Model identifier
            max_tokens: Max tokens parameter
            temperature: Temperature parameter

        Returns:
            SHA256 hash as hex string
        """
        # Combine all parameters that affect the response
        combined = (
            f"system_prompt:{system_prompt}\n"
            f"user_prompt:{user_prompt}\n"
            f"model:{model}\n"
            f"max_tokens:{max_tokens}\n"
            f"temperature:{temperature}"
        )

        return hashlib.sha256(combined.encode()).hexdigest()

    def get_cached_sql(self, cache_key: str) -> Optional[str]:
        """
        Retrieve cached SQL response.

        Args:
            cache_key: Hash generated by get_cache_key

        Returns:
            SQL query string if cached, None if cache miss
        """
        if cache_key in self.index:
            cached_file = self.cache_dir / cache_key / "sql_response.txt"
            if cached_file.exists():
                self.hits += 1
                return cached_file.read_text()

        self.misses += 1
        return None

    def save_sql_cache(self, cache_key: str, sql_response: str,
                       temperature: float, metadata: Optional[Dict] = None) -> None:
        """
        Save SQL response to cache.

        Only caches deterministic responses (temperature=0.0).

        Args:
            cache_key: Hash generated by get_cache_key
            sql_response: SQL query string from API
            temperature: Temperature used in API call
            metadata: Optional metadata for index (e.g., model, question_id)
        """
        # Only cache deterministic calls
        if temperature != 0.0:
            return

        # Create cache entry directory
        cache_entry_dir = self.cache_dir / cache_key
        cache_entry_dir.mkdir(parents=True, exist_ok=True)

        # Save SQL response file
        sql_file = cache_entry_dir / "sql_response.txt"
        sql_file.write_text(sql_response)

        # Update index (thread-safe: acquire lock before modifying)
        with self._index_lock:
            index_entry = {
                'sql_file': str(sql_file.relative_to(self.run_dir)),
                'temperature': temperature
            }
            # Add optional metadata
            if metadata:
                index_entry.update(metadata)

            self.index[cache_key] = index_entry

        # Save using atomic write (lock is inside _save_index)
        self._save_index()

    def get_cache_stats(self) -> Dict:
        """
        Get cache performance statistics.

        Returns:
            Dict with hits, misses, total, hit_rate, estimated_savings
        """
        total = self.hits + self.misses
        hit_rate = (self.hits / total * 100) if total > 0 else 0

        # Estimate savings: ~$0.01 per cached Phase 2 SQL generation call
        estimated_savings = self.hits * 0.01

        return {
            'hits': self.hits,
            'misses': self.misses,
            'total': total,
            'hit_rate': hit_rate,
            'estimated_savings': estimated_savings
        }
